"""


GWAS pipeline 


Requirements for input:


1. To remain sensible, it would be required to proivde a "sample sheet" in tsv format.
   There should at least be two columns: 
   	sample, file
   The read orientation would be inferred.  For now, we assume that the output from
   different lanes are merged - will extend it

2. If our input is already bam - for now i think it is better to extract fastq reads
   and realign so there are no software artifacts.


"""


# Move params to a config file - keep like this for now



hapmap_resource_vcf 			= "assets/vcf/hapmap_3.3.hg38.vcf.gz"
dbsnp_resource_vcf   			= "assets/vcf/Homo_sapiens_assembly38.dbsnp138.vcf"
one_thousand_genomes_resource_vcf 	= "assets/vcf/1000G_omni2.5.hg38.vcf.gz"
omni_resource_vcf 			= "assets/vcf/1000G_omni2.5.hg38.vcf.gz"
bwaindex				= "assets/bwaindex/hg38"

# Check the dbsnp ref
dbsnp_known_sites_vcf = "assets/vcf/Homo_sapiens_assembly38.dbsnp138.vcf" 
mills_and_1000_gold_standard = "assets/vcf/Mills_and_1000G_gold_standard.indels.hg38.vcf.gz"
hg38_known_indels = "assets/vcf/Homo_sapiens_assembly38.known_indels.vcf.gz"






config["inputdir"] = None if "inputdir" not in config else config["inputdir"]
config["sampletable"] = None if "sampletable" not in config else config["sampletable"]



def makeoutputs():
        global config

        if config["inputdir"] is not None:
                fastafiles = glob("%s/*.fastq.gz"%config["inputdir"])

        if config["sampletable"] is not None:
                sample_dataframe = pd.read_csv(config["sampletable"]).set_index("prefix")
                sample_dataframe["sample"] = sample_dataframe.index.values
                return sample_dataframe

        sample_dataframe = dumbrename.getFastqPrefixes(fastafiles,dohex=True)
        sample_dataframe = sample_dataframe[sample_dataframe.counts == 2]
        return sample_dataframe





# Should move this to a proper config file

sample_dataframe = makeoutputs()




# Placeholder for now 
rule all:

	final=expand("output/{sample}/final.txt", sample=sample_dataframe["sample"].drop_duplicates.values()),
	


# Pretty ugly - but it willl work for now
rule trimming:
	input: 
		FR=lambda wildcards: samplesheet.loc[wildcards.sample].values[0]
		RR=lambda wildcards: samplesheet.loc[wildcards.sample].values[1]

	output: 
		FR="output/{sample}/{sample}_R1.fq.gz",
		RR="output/{sample}/{sample}_R2.fq.gz",
		FRu="output/{sample}/{sample}_U_R1.fq.gz",
		RRu="output/{sample}/{sample}_U_R2.fq.gz"
		

	shell:
		"trimmomatic PE -threads {threads} {input.FR} {input.RR} {output.FR} {output.FRu} {output.RR} {output.RRu} "
		"SLIDINGWINDOW:4:20"

# Not the correct way - need to configure for .alt files too
rule bwa_mapping:
	input: 
		FR=rules.trimming.output.FR,
		RR=rules.trimming.output.RR
	output:
		bam="output/mapping/{sample}.bam",
		bamindex="output/mapping/{sample}.bam.bai"
		bam_unmapped="output/mapping/{sample}_unmapped.bam"

	params: index=config["bwaindex"]
	threads: 4
	shell:
		"bwa mem -K 100000000 -Y {params.index} -t {threads} -R '@RG\tID:{wildcards.sample}\tSM:{wildcards.sample}' -R 'SM={wildcards.sample}' {input.FR} {input.RR} |"
		"tee >(samtools view -f 4 -o {output.bam_unmapped}) >(samtools view -bu -F 4 | samtools sort -o {output.bam}) &&"
		"samtools index {output.bam}"


rule markduplicates:
	input:
		bai=rules.bwa_mapping.output.bamindex,
		bam=rules.bwa_mapping.output.bam
	output:
		bam="output/mapping/{sample}.markduplicates.bam",
		metrics="output/reports/{sample}.markduplicates.metrics.txt"

	shell:
		"picard MarkDuplicates I={input.bam} O={output.bam} M={output.metrics} ASSUME_SORT_ORDER=coordinate"



#This takes te samples directly from markduplicates. As suggested, we may need to downsample first

rule downsample:
	input:
		bam=rules.markduplicates.output.bam
	output:
		bam="output/mapping/{sample}.downsample.bam"
	params:
		fraction=0.2
	shell:
		"picard DownsampleSam I={input.bam} O={output.bam} P={params.fraction} CREATE_INDEX=true"


rule bqsr:
	input:
		bam=rules.downsample.output.bam

	output:
		bqsr="output/bqsr/{sample}.bqsr"
	params:
		refernce_fasta="path_to_hg38",
		knownSites_dbsnp="{dbsnp_known_sites_vcf}",
		knownSites_mills="{mills_and_1000_gold_standard}",
		knownSites_indel="{hg38_known_indels}",
		optional_flags="--rf BadCigar --preserve_qscores_less_than 6",
		regions="-L chr1 -L chr2 -L chr3 -L chr4 -L chr5 -L chr6 -L chr7 -L chr8 -L chr9 -L chr10 -L chr11 -L chr12 -L chr13 -L chr14 -L chr15 -L chr16 -L chr17 -L chr18 -L chr19 -L chr20 -L chr21 -L chr22"
	shell:
		"gatk BaseRecalibrator -I {input.bam} -R {params.reference_fasta} -O {output.bqsr}"
		"--known-sites {params.knownSites_dbsnp} "
		"--known-sites {params.knownSites_dbsnp} "
		"--known-sites {params.known_Sites_indel} "
		"{params.optional_flags} "


rule apply_bqsr:
	input:
		bam=rules.markduplicates.output.bam,
		bqsr=rules.bqsr.output.bqsr
	params:
		reference="hg38_reference",
		optional_flags="--globalQScorePrior -1.0 --preserve_qscores_less_than 6 --useOriginalQualities --create-output-bam-index",
		compression_flags="-SQQ 10 -SQQ 20 -SQQ 30"
	output:
		bam="output/mapping/{sample}.recalibrated.bam"

	shell:
		"gatk ApplyBQSR -R {params.reference} -I {input.bam} -bqsr{input.bqsr} -O {output.bam} --disable_indel_quanls "
		"{params.optional_flags} {params.compression_flags}"	

rule haplotypecaller:
	input:
		bam=rules.apply_bqsr.output.bam
	params:
		reference="hg38_reference",
		other_options=" -G StandardAnnotation -G StandardHGAnnotation -G AS_StandardAnnotation"
		
	output:
		gvcf="output/haplotypecaller/{sample}.g.vcf.gz"
	
	
	shell:
		"gatk HaplotypeCaller -R {params.reference} -I {input.bam} -O {output.gvcf} {params.other_options}"



rule gcvfreblock:
	input:
		vcf=rules.haplotypecaller.output.gvcf,
	output:
		gvcfeblocked="output/haplotypecaller/{sample}.g.reblocked.vcf.gz"
	params:
		standard="-drop-low-quals -do-qual-approx --floor-blocks -GQB 10 -GWB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60",
		reference="hg38_reference"

	shell:
		"gatk ReblockGVCF -R {input.reference} -V {input.vcf} -O {gvcfreblocked}"


rule gvcf_samplemap:
	input:
		expand("output/haplotypecaller/{sample}.g.reblocked.vcf.gz", sample=wildcards.sample)
	output
		"output/samplemap.tsv"
	shell:
		"python3 scripts/joinsamples.py -i {input}"



rule genomicsdb:
	input:
		vcfmap=rules.gvcf_samplemap.output

	output:
		directory("output/genomicdb")
	params:
		standard=" --batch-size 50 -L 20 --reader-threads {threads} --merge-input-intervals --consolidate --tmp-dir tmp/"

	shell:
		"gatk GenomicsDBImport --genomicsdb-workspace-path {output} --sample-name-map {input} {params}"



rule genotypevcf:
	input:
		rules.genomicsdb.output
	output:
		"output/genotypes/genotypes.vcf.gz"

	params:
		standard=" -R hg38_reference -D dbsnp_file -G StandardAnnotation --only-output-calls-starting-in-intervals "
			 " --use-new-qual-calculator  -L interval --merge-input-intervals -V gendb://{input}"
	shell:
		"gatk GenotypeGVCFs {params.standard} -O {output}"

# fill in resource vcf files
rule vqsr:
	input:
		rules.genotypevcf.output
	params:
		standard=" -R hg38_reference --trust-all-polymorphic -trache ${sep=' -tranche ' recalibration_tranche_values}"
			 " -an ${sep=' -an ' recalibration_annotation_values} -mode SNP "
			 " --resource:hapmap,known=false,training=true,truth=true,prior=15 ${hapmap_resource_vcf} "
			 " --resource:omni,known=false,training=true,truth=true,prior=12 ${omni_resource_vcf} "
			 " --resource:1000G,known=false,training=true,truth=false,prior=10 ${one_thousand_genomes_resource_vcf} "
			 " --resource:dbsnp,known=true,training=false,truth=false,prior=7 ${dbsnp_resource_vcf} "
	output:
		recal="output/genotypes/genotypes.recal.vcf.gz",
		tranches="output/genotypes/tranches",
		model="output/genotypes/model.report"


rule applyvqsr:
	input:
		recal=rules.vqsr.output.recal,
		tranches=rules.vqsr.output.tranches,
		model=rules.vqsr.output.model,
		vcf=rules.genotypevcf.output

	params:
		standard="-R hg38_reference --recal-file {input.recal} --tranches-file {input.tranches} -mode SNP --truth-sensitivity-filter-level 0.99 --use-allele-specific-annotations --create-output-variant-index true"

	output:
		recalvcf="output/genotypes/genotypes.recal.vcf.gz"
	shell:
		"gatk ApplyVQSR {params.standard} -O {output.recalvcf} -V {input.vcf}"

		


	

	
	
		

		
